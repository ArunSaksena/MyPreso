samp_mean[i] <- mean(samp)
samp_sd[i] <- sd(samp)
}
lower <- samp_mean - 1.96 * samp_sd/sqrt(n)
upper <- samp_mean + 1.96 * samp_sd/sqrt(n)
c(lower[1], upper[1])
plot_ci(lower, upper, mean(population))
?pnorm
qnorm(0.99)
qnorm(0.95)
qnorm(0.975)
qnorm(0.995)
pnorm(-0.33)
qnorm(0.4)
68-70
-2/3.3
pnorm(-0.606)
qnorm(0.82)
0.8413-0.1587
pnorm(-2)
pnorm(2)
0.977-0.022
pnorm(-3)
pnorm(3)
pnorm(1000)
qnorm(0.01)
18.2*6/6.5
?pnorm()
pnorm(16.8)
pnorm(16.8, lower.tail = FALSE)
9.51 - 10
4.65/sqrt(40)
-0.49/0.735
pnorm(0)
pnorm(-0.667)
qnorm(0.025)
qnorm(0.1)
1.281*18/4
5.76*5.76
sqrt(12.5)
15/3.535
pnorm(0)
1 - pnorm(4.243)
?dbinom
dbinom(8, size = 10, prob = 0.5)
sum(dbinom(8:10, size = 10, prob = 0.5))
0.5^10
45*0.5^10
pnorm(-0.87)
qnorm(0.025)
?matrix
A <- matrix(c(3, 2, 4, 16), nrow = 2)
A
?solve
solve(A) %*% A
solve(A)
B <- matrix(c(3, 2, 4, 16, 17, 23, 1, 0, -23), nrow = 3)
B
solve(B)
solve(B) %*% B
C <- matrix(c(0, 0, 0, 0, 0, 0, 0, 0, 0), nrow = 3)
C
solve(C)
solve()
?solve()
?tstat
?pnorm
?t
?pt
pt(2, df=50)
1 - pt(2. df=50)
2*(1 - pt(2, df=50))
2*(1 - pt(2, df=10))
2*(1 - pnorm(2))
2 * pt(2.24, df = 21, lower.tail = FALSE)
load(url("http://bit.ly/dasi_nc"))
head(nc)
summary(nc)
gained_clean <- na.omit(nc$gained)
n <- length(gained_clean)
n
boot_means <- rep(NA, 100)
class(boot_means)
for (i in 1:100) {
boot_sample <- sample(gained_clean, n, replace = TRUE)
boot_means[i] <- mean(boot_sample)
}
class(boot_means)
boot_means
hist(boot_means)
quantile(boot_means, c(0.05, 0.95))
SE <- sd(boot_means)
SE
?qnorm
qnorm(0.95)
xbar <- mean(boot_means)
xbar
xbar + 1.65 * SE
xbar - 1.65 * SE
source("http://bit.ly/dasi_inference")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.9, est = "mean", boot_method = "perc")
SE
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "mean", boot_method = "perc")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "mean", boot_method = "se")
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95, est = "median", boot_method = "se")
?boxplot
boxplot(nc$weigth ~ nc$habit)
boxplot(nc$weight ~ nc$habit)
by(nc$weight, nc$habit, mean)
by(nc$weight, nc$habit, length)
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ht", null = 0, alternative = "twosided", method = "theoretical")
inference(y = nc$weight, x = nc$habit, est = "mean", type = "ci", null = 0, alternative = "twosided", method = "theoretical")
head(nc)
nc[1:20]
nc[1:20,]
nc[50:60,]
nc[400:450,]
nc[800:850,]
nc[900:950,]
maturemoms <- subset(nc, nc$mature %in% "mature mom")
youngmoms <- subset(nc, nc$mature %in% "younger mom")
head(youngmoms)
summary(maturemoms$mature)
summary(maturemoms$mage)
summary(youngmoms$mage)
load(url("http://bit.ly/dasi_gss_ws_cl"))
head(gss)
boxplot(gss$wordsum ~ gss$class)
summary(gss)
by(gss$wordsum, gss$class, summary)
inference(y = gss$wordsum, x = gss$class, est = "mean", type = "ht", alternative = "greater", method = "theoretical")
?qt
qt(0.05, df = 24)
75/40.13
pnorm(2.36, lower-tail = FALSE)
pnorm(2.36, lower.tail = FALSE)
source("http://bit.ly/dasi_inference")
load(url("http://www.openintro.org/stat/data/atheism.RData"))
head(atheism)
dim(atheism)
i <- 1
sum <- 0
for (i in 1:nrow(atheism)) {
if (atheism[i,1] == "Afghanistan") {
sum <- sum + 1
}
}
sum
?sum
sum((atheism[:,1] == "Argentina"))
sum((atheism[,1] == "Argentina"))
sum((atheism[:,1] == "Australia"))
sum((atheism[,1] == "Australia"))
sum((atheism[,1] == "Afghanistan"))
sum((atheism[,1] == "Australia"), na.rm = FALSE)
sum((atheism[,1] == "Australia"), na.rm = TRUE)
ussum <- 0
for (i in 1:nrow(atheism)) {
if (atheism[i,1] == "United States") {
ussum <- ussum + 1
}
}
ussum
i <- 1
ussum <- 0
for (i in 1:nrow(atheism)) {
if (atheism[i,1] == "United States") {
ussum <- ussum + 1
}
}
ussum
head(atheism)
i
i <- 1
ussum <- 0
for (i in 1:nrow(atheism)) {
if (atheism$nationality == "United States") {
ussum <- ussum + 1
}
}
i
ussum
i <- 1
ussum <- 0
for (i in 1:nrow(atheism)) {
if (atheism[i,1] == "United States") {
ussum <- ussum + 1
}
}
i
ussum
us12 <- subset(atheism, atheism$nationality == "United States" & atheism$year == "2012")
head(us12)
dim(us12)
i <- 1
ussum <- 0
for (i in 1:nrow(atheism)) {
if ((atheism[i,1] == "United States") & (atheism[i,3] == "2012")) {
ussum <- ussum + 1
}
}
ussum
i <- 1
usatheist <- 0
for (i in 1: nrow(us12)) {
if (us12[i,2] == "atheist") {
usatheist <- usatheist + 1
}
}
usatheist
usatheist / nrow(us12)
inference(us12$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
0.0634 - 0.0499
n <- 1000
p <- seq(0, 1, 0.01)
me <- 2 * sqrt(p * (1 - p)/n)
plot(me ~ p)
?inference
??inference
?inference()
inference()
?install.packages
available.packages()
install.packages("caret")
install.packages("caret", dependencies = c("Depends", "Suggests"))
library(caret)
library(kernlab)
data(spam)
head(spam)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
dim(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.75, list = FALSE)
training <- myData[inTrain,]
testing <- myData[-inTrain,]
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=training)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library("rpart.plot")
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=testing)
names(testing)
?cbind
k <- data.frame(1:10)
k
View(k)
View(k)
k <- as.data.frame(setNames(replicate(119,numeric(0), simplify = F), names[testing])
k <- as.data.frame(setNames(replicate(119,numeric(0), simplify = F), names[testing])
?replicate
k <- data.frame(replicate(119,numeric(0), simplify = F))
dim(k)
names(testing)
colnames(k) <- names(testing)
k
?rbind
k[1,] <- 0
k
dim(k)
names(k)
k[2,] <- 0
k[3,] <- 0
k[4,] <- 0
k[1, "TotalIntenCh2"] <- 23000
k[2, "TotalIntenCh2"] <- 50000
k[3, "TotalIntenCh2"] <- 57000
k[1, "FiberWidthCh1"] <- 10
k[2, "FiberWidthCh1"] <- 10
k[3, "FiberWidthCh1"] <- 8
k[1, "PerimStatusCh1"] <- 2
k[4, "PerimStatusCh1"] <- 2
k[2, "VarIntenCh4"] <- 100
k[3, "VarIntenCh4"] <- 100
k[4, "VarIntenCh4"] <- 100
k[4, "FiberWidthCh1"] <- 8
dim(k)
predict(modFit,newdata=k)
names(k)
k[, "Class"] <- as.factor(k[, "Class"])
predict(modFit,newdata=k)
table(testing$class)
class(testing$class)
class(testing$Class)
table(testing$Class)
?as.factor
k[, "Class"] <- as.factor(k[, "Class"], levels = c("PS", "WS"))
k[, "Class"] <- factor(levels = c("PS", "WS"))
class(k$Class)
table(k$Class)
predict(modFit,newdata=k)
set.seed(125)
modFit <- train(Class ~ .,method="rpart",data=training)
print(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=k)
k[, "Case"] <- as.factor(k[, "Case"])
k[, "Case"] <- factor(levels = c("Test", "Train"))
predict(modFit,newdata=k)
predict(modFit,newdata=k[1,])
install.packages("pgmm")
library(pgmm)
data(olive)
names(olive)
olive = olive[,-1]
names(olive)
inTrain <- createDataPartition(y=olive$Area, p=0.7, list=FALSE)
training <- olive[inTrain,]
testing <- olive[-inTrain,]
modFit <- train(Area ~ .,method="rpart",data=training)
print(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
head(olive)
table(olive$Area)
newdata = as.data.frame(t(colMeans(olive)))
?tree
predict(modFit,newdata=newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(trainSA)
modFit<- train(chd ~ age + tobacco + typea + obesity + alcohol + ldl, method = "glm", family = "binomial", data=trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
pred1 <- predict(modFit, trainSA)
pred2 <- predict(modFit, testSA)
missClass(trainSA, pred1)
missClass(testSA, pred2)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
class(vowel.train)
class(vowel.test)
head(vowel.train)
vowel.train$y -> as.factor(vowel.train$y)
?factor
vowel.train$y -> factor(vowel.train$y)
class(vowel.train$y)
vowel.train$y <- as.factor(vowel.train$y)
class(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(caret)
?train
mod1 <- train(y ~ ., method = "rf", data = vowel.train, trControl = trainControl(method = "cv"), number = 3)
?train
mod2 <- train(y ~ ., method = "gbm", data = vowel.train)
mod1
mod2
pred1 <- predict(mod1, vowel.test)
pred1
pred2 <- predict(mod2, vowel.test)
sum(dbinom(4:20, 20, 0.1))
dbinom(1, 5, 0.2)
dbinom(2, 10, 0.1)
dbinom(2, 10, 0.2)
dbinom(3, 15, 0.1)
dbinom(3, 15, 0.2)
0.1285+0.25
.1285/.3785
library(C50)
install.packages("C50")
library(C50)
data(churn)
head(churnTrain)
dim(churnTrain)
type(churnTrain)
class(churnTrain)
?unique
predictors <- names(churnTrain)[names(churnTrain) != "churn"]
class(predictors)
predictors
numerics <- c("account_length", "total_day_calls", "total_night_calls")
procValues <- preProcess(churnTrain[, numerics], method = c("center", "scale", "YeoJohnson"))
library(caret)
procValues <- preProcess(churnTrain[, numerics], method = c("center", "scale", "YeoJohnson"))
trainScaled <- predict(procValues, churnTrain[, numerics])
testScaled <- predict(procValues, churnTest[, numerics])
?preProcess
dim(trainScaled)
head(TrainScaled)
head(trainScaled)
procValues
?t
?qt
pt(0.025, 29, lower.tail = TRUE)
pt(0.025, df = 29, lower.tail = TRUE)
qt(0.025, df = 29, lower.tail = TRUE)
sqrt(4040)
data()
data(mtcars)
mtcars
?mtcars
model1 <- lm(mpg ~ cyl + hp + am, data = mtcars)
model1
?plot
plot(mtcars$cyl, mtcars$mpg, type = "l")
?plot
plot(mtcars$cyl, mtcars$mpg, type = "p")
plot(mtcars$cyl, mtcars$hp, type = "p")
plot(mtcars$hp, mtcars$mpg, type = "p")
plot(mtcars$am, mtcars$mpg, type = "p")
summary(model1)
model2 <- lm(mpg ~ cyl + hp + wt, data = mtcars)
summary(model2)
model3 <- lm(mpg ~ cyl + wt, data = mtcars)
summary(model3)
?predict
xVal <- data.frame()
dim(xVal)
mtcars
xVal[1,1] <- 6
xVal[1,2] <- 110
xVal[1,3] <- 2.62
xVal
newdata <- xVal
newdata
p1 <- predict(model2, newdata, interval = ("prediction"))
myNames <- c("cyl", "hp", "wt")
myNames
names(newdata) <- myNames
newdata
p1 <- predict(model2, newdata, interval = ("prediction"))
p1
p1[1,1]
?data.frame()
d1 <- data.frame(1, 1, 1)
d1
names(d1) <- c("cyl", "hp", "wt")
d1
dim(d1)
class(d1)
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
?function()
?function
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
mtcars
a <- as.numeric("8")
a
b <- "8"
b
a <- as.numeric(b)
a
class(a)
min(mtcars$hp)
max(mtcars$hp)
335 - 52
283 /2
141 + 52
max(mtcars$wt)
min(mtcars$wt)
?mtcars
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
?mfrow
?par
par(mfrow = c(1,2))
?plot
plot(hp, mpg, data = mtcars)
plot(mtcars$hp, mtcars$mpg)
plot(mtcars$wt, mtcars$mpg)
?plot
plot(mtcars$hp, mtcars$mpg, xlab = "Horse Power", ylab = "MPG")
plot(mtcars$hp, mtcars$mpg, xlab = "Horse Power", ylab = "MPG", col = "blue")
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
shiny::runApp('~/Documents/Mac Documents September 1 2011/Data Products/Project')
library(shiny)
library(ggplot2)
library(gridExtra)
getwd()
setwd("/Users/arsaksen/Documents/Mac Documents September 1 2011")
dir()
setwd("Data Products")
dir()
setwd("Preso")
dir()
library(slidify)
library(shiny)
library(datasets)
library(knitr)
publish_github(ArunSaksena, MyPreso)
getwd()
publish_github(ArunSaksena, MyPreso)
getwd()
dir()
publish_github(ArunSaksena, MyPreso)
